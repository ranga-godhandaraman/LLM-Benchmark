{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/JErwl6ylfpIkJtjfBFJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranga-godhandaraman/LLM-Benchmark/blob/main/MMLU_SQUAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlhx3PwZtAte"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AlbertTokenizer, AlbertModel, DistilBertTokenizer, DistilBertModel\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ALBERT model and tokenizer\n",
        "albert_model_name = 'albert-base-v2'\n",
        "albert_tokenizer = AlbertTokenizer.from_pretrained(albert_model_name)\n",
        "albert_model = AlbertModel.from_pretrained(albert_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc1fUVxjtJTp",
        "outputId": "b29931d5-6e85-42ea-f4d6-a19738e649b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained DistilBERT model and tokenizer\n",
        "distilbert_model_name = 'distilbert-base-uncased'\n",
        "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(distilbert_model_name)\n",
        "distilbert_model = DistilBertModel.from_pretrained(distilbert_model_name)"
      ],
      "metadata": {
        "id": "lP7AHXeotJWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"Diabetes management traditionally relies on standardized approaches, neglecting individual needs. Data science offers a transformative opportunity to personalize care. This article explores the impact of data science on diabetes care, focusing on key areas of application and the ethical considerations involved. Iâ€™ve combined insights from relevant research, medical literature, and current technology advancements in data science.Data science holds significant potential to revolutionize diabetes care by fostering personalized and effective treatment strategies. However, ensuring patient privacy and ethical data-driven practices remain crucial. This integrated approach holds promise for improved outcomes and quality of life for individuals living with diabetes.Instead of imagining a fire, think of predicting a storm. Data science analyzes your health data (blood sugar, family history, etc.) to identify early signs of trouble. This allows doctors to recommend preventive measures like healthy eating, exercise, or even medication, potentially delaying or even preventing diabetes altogether.Think of this like creating a unique recipe just for your taste buds. Data science considers your genetic makeup, daily routines, and even your living environment to craft a personalized treatment plan. This could involve specific food choices, exercise programs, or medication dosages that are most effective for you.Imagine having a fitness tracker for your whole body. Wearable devices and sensors continuously collect data about your blood sugar, activity levels, and sleep patterns. Doctors can then analyze this data remotely, allowing them to adjust your treatment plan in real time and prevent potential complications before they arise.Think of this as unlocking a secret code. Data science analyzes massive datasets of patient responses to different medication combinations. This allows doctors to identify the unique mix that will be most effective for you, with minimal side effects. This personalized approach can significantly improve your treatment outcomes and overall well-being.Data security is like building a fortress around your health information. Robust encryption methods and strict data protection regulations ensure that your medical data stays safe and confidential. You can be confident that your information is only used for your healthcare and is never shared without your consent.\""
      ],
      "metadata": {
        "id": "2TzIzLoTtJYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "albert_inputs = albert_tokenizer(input_text, return_tensors=\"pt\")\n",
        "distilbert_inputs = distilbert_tokenizer(input_text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "o5xJNQs9tJbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALBERT Forward pass\n",
        "with torch.no_grad():\n",
        "    albert_outputs = albert_model(**albert_inputs)"
      ],
      "metadata": {
        "id": "nJPriindtJeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DistilBERT Forward pass\n",
        "with torch.no_grad():\n",
        "    distilbert_outputs = distilbert_model(**distilbert_inputs)"
      ],
      "metadata": {
        "id": "Q1qFHX9TtJgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get layer activations\n",
        "albert_layer_activations = albert_outputs.last_hidden_state\n",
        "distilbert_layer_activations = distilbert_outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "BKvUD4U3tJjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate layer utilization\n",
        "albert_layer_utilization = torch.mean((albert_layer_activations != 0).float(), dim=0).numpy()\n",
        "distilbert_layer_utilization = torch.mean((distilbert_layer_activations != 0).float(), dim=0).numpy()"
      ],
      "metadata": {
        "id": "ufyEZuUPtJmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MMLU\n",
        "albert_mmlu = np.mean(np.max(albert_layer_utilization, axis=1))\n",
        "distilbert_mmlu = np.mean(np.max(distilbert_layer_utilization, axis=1))"
      ],
      "metadata": {
        "id": "LH9gFtentJpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ALBERT MMLU:\", albert_mmlu)\n",
        "print(\"DistilBERT MMLU:\", distilbert_mmlu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKwZWRWgtJrx",
        "outputId": "5e2b366a-6783-4878-8c93-af2cc01d7109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALBERT MMLU: 1.0\n",
            "DistilBERT MMLU: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With SQUAD dataset"
      ],
      "metadata": {
        "id": "MBiKTeP1t0WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers datasets\n",
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6629mdXtJuY",
        "outputId": "36ba9df0-a557-477e-a9b5-525724885825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# Load SQuAD dataset\n",
        "squad_dataset = load_dataset(\"squad\")"
      ],
      "metadata": {
        "id": "1aRnThPstJxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a few passages and questions from SQuAD\n",
        "passages = squad_dataset['train']['context'][:10]\n",
        "questions = squad_dataset['train']['question'][:10]"
      ],
      "metadata": {
        "id": "imp_d6wVtJ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As we have already initialized, we don't do it now again!!\n",
        "# # Initialize ALBERT tokenizer and model\n",
        "# albert_tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "# albert_model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "# # Initialize DistilBERT tokenizer and model\n",
        "# distilbert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "# distilbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "denK9PJCtJ24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "ucIR-eCitJ5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate MMLU for a given model and tokenizer\n",
        "def calculate_mmlu(model, tokenizer, passages):\n",
        "    inputs = tokenizer(passages, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    activations = outputs.last_hidden_state\n",
        "    layer_utilization = torch.mean((activations != 0).float(), dim=0)\n",
        "    mmlu = torch.mean(torch.max(layer_utilization, dim=1).values).item()\n",
        "    return mmlu"
      ],
      "metadata": {
        "id": "GhNXiS48tJ8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MMLU for ALBERT\n",
        "albert_mmlu = calculate_mmlu(albert_model, albert_tokenizer, passages)\n",
        "print(\"ALBERT MMLU:\", albert_mmlu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQEZYGkytJ_P",
        "outputId": "57b78a96-29ed-481f-9334-48ef8893989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALBERT MMLU: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MMLU for DistilBERT\n",
        "distilbert_mmlu = calculate_mmlu(distilbert_model, distilbert_tokenizer, passages)\n",
        "print(\"DistilBERT MMLU:\", distilbert_mmlu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFTKBcwwtKCK",
        "outputId": "32b3ce42-8058-45d0-bbb6-2a5f614ff25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT MMLU: 1.0\n"
          ]
        }
      ]
    }
  ]
}